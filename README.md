# InSight

## Dartmouth CS65 Final Project

### Project Description:
InSight is an Android application aimed at improving the quality of life of the visually imapaired.
Using CameraX and Google Firebase, this app helps the visually impaired by providing features like:
- Using Firebase authentication to log users in via speech
- Providing audio feedback on button presses using Google's text to speech engine
- Using Firebase ML Kit's text recogintion API to recognize text and provide audio feedback
- Using Firebase ML Kit's image recognition API to recognize objects in the users surrounding, and provide audio feedback
- Add-on features like 'Read Tutorials', and 'Provide Feedback' that improve the users experience


### Original Pitch
[See the original project pitch](https://docs.google.com/presentation/d/1PjDBnxKh9KSKOLvDSTeLFw40MYGL8JayIdCbSn8xo9Q/edit?usp=sharing)


### Show and Tell 1:
#### MVC Diagram:
![](images/mvc_diagram.png)


#### Who Is Doing What:
So far:
- Sylvester:UI, Native Android audio feedback and perception
- Sebastian: Firebase ML kit(Barcode scanner, text recognition, object recognition)
- Chris: UI, CameraX research

From here on out:
- Working together through specific feature tasks


#### Goals for Show and Tell 2:
- Have a custom Firebase authenticaton that allows users to log in using their voice
- Have text recognition working
- Completed UI




### Show and Tell 2:

#### Thread Design Diagram:
![](images/thread_mvc.png)

#### Update
- Finished 95% of the UI
- Finished implementing the text-recogniton feature
- Finished 75% of the audio feedback
- Finished Navigation Drawer Add-ons

#### What's Next?
- Finish the app!
- Finish implementing the realtime database
- Add image description funcitonality
- If there's time, add barcode, color, or currency recogniton


### Download APK (https://drive.google.com/file/d/1rCnARfaD0p58YvcCweHj1kzi9GL4qgWc/view?usp=sharing)

### Google Presentation




